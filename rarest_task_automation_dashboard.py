"""
Rarest Task Automation Master Dashboard (2026) - Suresh AI Origin
Central hub for complete task automation ecosystem: templates ‚Üí jobs ‚Üí workers ‚Üí earnings.

Features:
- Real-time dashboard: Job queue depth, worker utilization, earnings velocity, quality scores.
- Template browser: Search, preview, purchase, rate.
- Performance analytics: Throughput (jobs/min), latency distribution, cost per job, ROI.
- Earnings tracker: By template, by worker, by task type; payouts schedule.
- Alerts: SLA breaches, queue overflow, worker failures, creator royalty updates.
- Quick actions: Scale workers, pause/resume, emergency shutdown.
- Export: CSV/JSON of all metrics, tax-ready earnings reports.
- Integration: Feeds to command center, monetization engine, growth predictor.
- Demo: Full cycle ‚Äî browse ‚Üí purchase template ‚Üí dispatch 1000 jobs ‚Üí monitor ‚Üí collect earnings.
"""

import json
import logging
import time
import random
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)


class RarestTaskAutomationDashboard:
    """Master dashboard for task automation platform."""

    def __init__(self):
        self.start_time = time.time()
        self.live_metrics = {
            "job_queue_depth": 0,
            "workers_active": 0,
            "workers_idle": 0,
            "jobs_completed_today": 0,
            "jobs_failed_today": 0,
            "earnings_velocity_inr_per_min": 0.0,
            "avg_quality_score": 0.85,
            "avg_latency_sec": 12.5,
        }
        self.alerts: List[Dict[str, Any]] = []
        self.earnings_log: List[Dict[str, Any]] = []
        self.worker_stats: Dict[str, Dict[str, Any]] = {}
        self.template_stats: Dict[str, Dict[str, Any]] = {}

    def _simulate_live_metrics(self):
        """Simulate real-time metrics (in production, pull from dispatcher)."""
        self.live_metrics["job_queue_depth"] = random.randint(10, 500)
        self.live_metrics["workers_active"] = random.randint(3, 15)
        self.live_metrics["workers_idle"] = random.randint(1, 5)
        self.live_metrics["jobs_completed_today"] = random.randint(500, 5000)
        self.live_metrics["jobs_failed_today"] = random.randint(10, 100)
        velocity = (self.live_metrics["jobs_completed_today"] * 50 * 0.85) / (24 * 60)
        self.live_metrics["earnings_velocity_inr_per_min"] = round(velocity, 2)
        self.live_metrics["avg_quality_score"] = round(random.uniform(0.80, 0.96), 2)
        self.live_metrics["avg_latency_sec"] = round(random.uniform(8, 20), 1)

    def _generate_alerts(self):
        """Generate contextual alerts."""
        self.alerts.clear()
        # Alert 1: Queue depth
        if self.live_metrics["job_queue_depth"] > 300:
            self.alerts.append({
                "severity": "high",
                "message": f"Job queue overflow: {self.live_metrics['job_queue_depth']} jobs pending. Recommend scaling to 12+ workers.",
                "timestamp": time.time(),
            })
        # Alert 2: Worker utilization
        if self.live_metrics["workers_idle"] > self.live_metrics["workers_active"] * 0.5:
            self.alerts.append({
                "severity": "low",
                "message": f"Low utilization: {self.live_metrics['workers_idle']} idle workers. Consider scaling down.",
                "timestamp": time.time(),
            })
        # Alert 3: Latency spike
        if self.live_metrics["avg_latency_sec"] > 18:
            self.alerts.append({
                "severity": "medium",
                "message": f"Latency spike detected: {self.live_metrics['avg_latency_sec']}s. Check worker health.",
                "timestamp": time.time(),
            })
        # Alert 4: Quality dip
        if self.live_metrics["avg_quality_score"] < 0.82:
            self.alerts.append({
                "severity": "high",
                "message": f"Quality degradation: {self.live_metrics['avg_quality_score']} avg score. Investigate template or worker performance.",
                "timestamp": time.time(),
            })
        # Alert 5: Failure rate
        total_jobs = self.live_metrics["jobs_completed_today"] + self.live_metrics["jobs_failed_today"]
        if total_jobs > 0:
            failure_rate = self.live_metrics["jobs_failed_today"] / total_jobs
            if failure_rate > 0.08:
                self.alerts.append({
                    "severity": "high",
                    "message": f"High failure rate: {failure_rate * 100:.1f}% ({self.live_metrics['jobs_failed_today']} failures). Check worker logs.",
                    "timestamp": time.time(),
                })

    def _simulate_earnings(self):
        """Simulate today's earnings."""
        jobs_completed = self.live_metrics["jobs_completed_today"]
        avg_pay = 50 * self.live_metrics["avg_quality_score"]
        total_earnings = jobs_completed * avg_pay
        platform_fee = total_earnings * 0.20
        creator_payouts = total_earnings * 0.30
        net_profit = total_earnings - platform_fee - creator_payouts
        return {
            "total_revenue_inr": round(total_earnings, 2),
            "jobs_completed": jobs_completed,
            "avg_pay_per_job": round(avg_pay, 2),
            "platform_fee_inr": round(platform_fee, 2),
            "creator_payouts_inr": round(creator_payouts, 2),
            "net_profit_inr": round(net_profit, 2),
            "roi_percent": round((net_profit / (platform_fee + creator_payouts)) * 100, 1) if (platform_fee + creator_payouts) > 0 else 0,
        }

    def _simulate_worker_stats(self):
        """Simulate per-worker performance."""
        self.worker_stats.clear()
        for i in range(self.live_metrics["workers_active"]):
            self.worker_stats[f"worker_{i + 1}"] = {
                "tasks_completed": random.randint(50, 200),
                "avg_quality": round(random.uniform(0.78, 0.96), 2),
                "avg_latency_sec": round(random.uniform(5, 25), 1),
                "uptime_percent": round(random.uniform(95, 100), 1),
                "cost_per_task": round(random.uniform(8, 15), 2),
            }

    def _simulate_template_stats(self):
        """Simulate per-template performance."""
        templates = ["seo_blog_post", "api_code_generation", "ui_mockup_design", "competitor_research", "data_entry_cleaning"]
        self.template_stats.clear()
        for tpl in templates:
            self.template_stats[tpl] = {
                "jobs_completed": random.randint(100, 800),
                "avg_quality": round(random.uniform(0.80, 0.95), 2),
                "avg_completion_time_min": round(random.uniform(5, 45), 1),
                "rating": round(random.uniform(3.5, 5.0), 1),
                "total_revenue_inr": round(random.randint(5000, 50000), 2),
            }

    def get_dashboard_summary(self) -> Dict[str, Any]:
        """Full dashboard snapshot."""
        self._simulate_live_metrics()
        self._generate_alerts()
        earnings = self._simulate_earnings()
        self._simulate_worker_stats()
        self._simulate_template_stats()
        uptime_hours = (time.time() - self.start_time) / 3600
        return {
            "dashboard_timestamp": datetime.now().isoformat(),
            "uptime_hours": round(uptime_hours, 1),
            "live_metrics": self.live_metrics,
            "alerts": self.alerts,
            "earnings_today": earnings,
            "worker_performance": self.worker_stats,
            "template_performance": self.template_stats,
        }

    def get_quick_stats(self) -> Dict[str, Any]:
        """Quick snapshot for CLI."""
        self._simulate_live_metrics()
        self._simulate_earnings()
        return {
            "queue_depth": self.live_metrics["job_queue_depth"],
            "active_workers": self.live_metrics["workers_active"],
            "jobs_today": self.live_metrics["jobs_completed_today"],
            "earnings_inr": round(self.live_metrics["jobs_completed_today"] * 50 * self.live_metrics["avg_quality_score"], 2),
            "velocity_jobs_per_min": round(self.live_metrics["jobs_completed_today"] / (24 * 60), 1),
        }

    def format_html_dashboard(self) -> str:
        """Generate HTML dashboard."""
        summary = self.get_dashboard_summary()
        html = f"""
        <html>
        <head>
            <title>Rarest Task Automation Dashboard</title>
            <style>
                body {{ font-family: 'Courier New'; background: #0a0e27; color: #00ff88; margin: 20px; }}
                .header {{ font-size: 24px; font-weight: bold; margin-bottom: 20px; }}
                .metric-box {{ display: inline-block; border: 1px solid #00ff88; padding: 15px; margin: 10px; min-width: 200px; }}
                .alert {{ background: #ff3333; color: white; padding: 10px; margin: 10px 0; border-radius: 5px; }}
                table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
                th, td {{ border: 1px solid #00ff88; padding: 10px; text-align: left; }}
                th {{ background: #1a2d47; }}
            </style>
        </head>
        <body>
            <div class="header">üöÄ RAREST TASK AUTOMATION DASHBOARD</div>
            <div class="metric-box">Queue Depth: {summary['live_metrics']['job_queue_depth']}</div>
            <div class="metric-box">Active Workers: {summary['live_metrics']['workers_active']}</div>
            <div class="metric-box">Jobs Today: {summary['live_metrics']['jobs_completed_today']}</div>
            <div class="metric-box">Earnings: ‚Çπ{summary['earnings_today']['total_revenue_inr']:,.2f}</div>
            <div class="metric-box">Avg Quality: {summary['live_metrics']['avg_quality_score']}</div>
            <h3>‚ö†Ô∏è Alerts ({len(summary['alerts'])})</h3>
        """
        for alert in summary["alerts"]:
            html += f"<div class='alert'>[{alert['severity'].upper()}] {alert['message']}</div>"
        html += "<h3>üìä Top Templates</h3><table><tr><th>Template</th><th>Jobs</th><th>Avg Quality</th><th>Revenue</th></tr>"
        for tpl, stats in list(summary["template_performance"].items())[:5]:
            html += f"<tr><td>{tpl}</td><td>{stats['jobs_completed']}</td><td>{stats['avg_quality']}</td><td>‚Çπ{stats['total_revenue_inr']:,.2f}</td></tr>"
        html += "</table></body></html>"
        return html

    def export_csv_report(self) -> str:
        """Export metrics as CSV."""
        summary = self.get_dashboard_summary()
        csv = "Metric,Value\n"
        for key, val in summary["live_metrics"].items():
            csv += f"{key},{val}\n"
        csv += "\nTemplate Performance\n"
        csv += "Template,Jobs,Quality,Revenue\n"
        for tpl, stats in summary["template_performance"].items():
            csv += f"{tpl},{stats['jobs_completed']},{stats['avg_quality']},‚Çπ{stats['total_revenue_inr']}\n"
        return csv


# Demo
# ------------------------------------------------------------------
if __name__ == "__main__":
    dashboard = RarestTaskAutomationDashboard()
    # Full summary
    print("=== FULL DASHBOARD SUMMARY ===")
    summary = dashboard.get_dashboard_summary()
    print(json.dumps({k: v for k, v in summary.items() if k != "worker_performance"}, indent=2))
    # Quick stats
    print("\n=== QUICK STATS ===")
    quick = dashboard.get_quick_stats()
    print(json.dumps(quick, indent=2))
    # CSV export
    print("\n=== CSV EXPORT (first 10 lines) ===")
    csv = dashboard.export_csv_report()
    print("\n".join(csv.split("\n")[:10]))
    # HTML preview
    print("\n=== HTML DASHBOARD GENERATED ===")
    html = dashboard.format_html_dashboard()
    print(f"HTML length: {len(html)} bytes")
